{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 19b9343b-f1f5-4184-b9f1-3d264b000b18\n",
      "Document processed successfully. Output saved to /tmp/output.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div>\n",
       "    <span style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Deploying </span> <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">llama</span>\n",
       "  </div>\n",
       "  \n",
       "\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">Uploading dependencies...</div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Success!</div>\n",
       "  \n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "      Deployment <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">llama</span>\n",
       "      will be ready in  a few seconds!\n",
       "    </div>\n",
       "  \n",
       "\n",
       "  <a href=\"https://us-east-1.aws.modelbit.com/w/christineoyiera/main/deployments/llama/apis\" target=\"_blank\" style=\"display: inline-block; margin-top: 12px;\" >\n",
       "    <div\n",
       "      style=\"display: inline-block; background-color: #845B99; border-radius: 0.375rem; color: white; cursor: pointer; font-size: 14px; font-weight: 700; padding: 8px 16px;\"\n",
       "      onmouseenter=\"this.style.background='#714488'\"\n",
       "      onmouseleave=\"this.style.background='#845B99'\"\n",
       "    >\n",
       "      View in Modelbit\n",
       "    </div>\n",
       "  </a>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployed successfully with Modelbit\n"
     ]
    }
   ],
   "source": [
    "import modelbit\n",
    "import nest_asyncio\n",
    "import tempfile\n",
    "from llama_parse import LlamaParse  # Ensure this is the correct module import\n",
    "import os\n",
    "import base64\n",
    "\n",
    "# Login to Modelbit\n",
    "mb = modelbit.login()\n",
    "\n",
    "# Apply `nest_asyncio` for compatibility with async frameworks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Securely get the Llama Cloud API Key\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\", \"llx-I2ak5Fd5jXCnZg95khu2RqUDTNSBNmVbqYmLdwKNkkBvrVWB\")\n",
    "\n",
    "# Define the fields to be extracted\n",
    "fields = [\n",
    "    \"Contract Number\", \"Amount\", \"Award Date\", \"Tender Title\", \"Eval Completion Date\", \n",
    "    \"Notification Of Award Date\", \"Sign Date\", \"Start Date\", \"End Date\", \n",
    "    \"Agpo Certificate Number\", \"Awarded Agpo Group Id\", \"Created By\", \"Terminated\", \n",
    "    \"Financial Year\", \"Quarter\", \"Tender Ref.\", \"PE Name\", \"Supplier Name\", \n",
    "    \"No. of B.O.I\", \"Created At\"\n",
    "]\n",
    "\n",
    "# Define parsing instructions to guide LlamaParse to extract the table with specific fields\n",
    "parsing_instructions = f\"\"\"\n",
    "Extract a structured table with the following fields:\n",
    "{', '.join(fields)}.\n",
    "\n",
    "Each field should be parsed as an individual column. \n",
    "Format date fields to YYYY-MM-DD where possible.\n",
    "For \"Amount\", extract numeric values only.\n",
    "Return the parsed data as a structured table or JSON.\n",
    "\"\"\"\n",
    "\n",
    "# Define deployment settings\n",
    "deploy_settings = {\n",
    "    \"env\": \"production\",\n",
    "    \"model_name\": \"parser_model\",\n",
    "    \"model_description\": \"A parser model for extracting information from PDF files and converting to Markdown\",\n",
    "    \"compute\": {\n",
    "        \"cpu\": 2,\n",
    "        \"gpu\": 1,\n",
    "        \"memory\": 8\n",
    "    },\n",
    "    \"batch_size\": 32,\n",
    "    \"input_data_format\": \"pdf\",\n",
    "    \"output_data_format\": \"markdown\",\n",
    "    \"model_versioning\": True\n",
    "}\n",
    "\n",
    "# Function to process PDF content with LlamaParse\n",
    "def llama(file_contents):\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        file_path = f\"{tmp_dir}/uploaded_file.pdf\"\n",
    "\n",
    "        file_contents = base64.b64decode(file_contents)\n",
    "        \n",
    "        # Write the received file contents as bytes to a temporary PDF file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(file_contents)\n",
    "\n",
    "        # Process the file with LlamaParse\n",
    "        try:\n",
    "            # Initialize the parser with specified instructions and API key\n",
    "            parser = LlamaParse(\n",
    "                api_key=LLAMA_CLOUD_API_KEY,\n",
    "                result_type=\"markdown\",  # Use \"table\" for structured data extraction\n",
    "                parsing_instructions=parsing_instructions\n",
    "            )\n",
    "            \n",
    "            # Load and parse the data\n",
    "            result = parser.load_data(file_path)\n",
    "            \n",
    "            # Check if the result is a list and process it accordingly\n",
    "            if isinstance(result, list):\n",
    "                # Join all table rows into a single markdown string\n",
    "                combined_text = \"\\n\".join([item.text for item in result if hasattr(item, 'text')])\n",
    "                return combined_text if combined_text else \"No text content found in document.\"\n",
    "            else:\n",
    "                # If result is not a list, return its text directly if it has any\n",
    "                return result.text if hasattr(result, 'text') else \"No text content found in document.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file with LlamaParse: {e}\")\n",
    "            return None\n",
    "\n",
    "# Example usage of the function\n",
    "try:\n",
    "    # Simulate reading a PDF file as bytes\n",
    "    with open(\"/home/clencyc/Dev/Llama_Parse/Package_1_Lot_2_Kulamawe_Modogashe_Consultancy_Services_Beneficial.pdf\", \"rb\") as file:\n",
    "        file_contents = file.read()\n",
    "\n",
    "    # Pass the file contents directly to the function\n",
    "    document_with_instruction = llama(file_contents)\n",
    "\n",
    "    if document_with_instruction:\n",
    "        # Optionally save the output\n",
    "        output_path = \"/tmp/output.md\"\n",
    "        with open(output_path, \"w\") as output_file:\n",
    "            output_file.write(document_with_instruction)\n",
    "        print(f\"Document processed successfully. Output saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"Document processing failed or no data found.\")\n",
    "\n",
    "    # Deploy the model using Modelbit\n",
    "    mb.deploy(llama)\n",
    "    print(\"Model deployed successfully with Modelbit\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during file processing or deployment: {e}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
