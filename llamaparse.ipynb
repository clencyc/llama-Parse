{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b82890da-a91c-42a2-a6cd-694f0fec8994\n",
      "[Document(id_='6be9ef33-05ac-40e3-8d1a-67fe04ec968a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Doc ID: 11b84b7d-3ac6-459d-8325-cbaca08b3aef\\nText: Doc ID: aa38dff9-23a9-4dd0-a41f-3b5f51a8e698 Text: [', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "deploy() got an unexpected keyword argument 'input_data_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m file_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m file_contents \u001b[38;5;241m=\u001b[39m file_object\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 61\u001b[0m \u001b[43mmb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllama\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Llama_Parse/venv/lib/python3.12/site-packages/modelbit/telemetry.py:127\u001b[0m, in \u001b[0;36meatErrorAndLog.<locals>.decorator.<locals>.innerFn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ModelbitError(error)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m cast(\u001b[38;5;167;01mException\u001b[39;00m, error)\n",
      "File \u001b[0;32m~/Dev/Llama_Parse/venv/lib/python3.12/site-packages/modelbit/telemetry.py:109\u001b[0m, in \u001b[0;36meatErrorAndLog.<locals>.decorator.<locals>.innerFn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m error: Optional[Union[\u001b[38;5;167;01mException\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m                       \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Store and raise outside the handler so the trace is more compact.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m   logEventToWeb(api\u001b[38;5;241m=\u001b[39mmbApi, userErrorMsg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenericMsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: deploy() got an unexpected keyword argument 'input_data_format'"
     ]
    }
   ],
   "source": [
    "import modelbit\n",
    "mb = modelbit.login()\n",
    "\n",
    "import tempfile\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "# Simulate receiving the file content from the React frontend\n",
    "file_path = \"/home/clencyc/Dev/Llama_Parse/Package_1_Lot_2_Kulamawe_Modogashe_Consultancy_Services_Beneficial.pdf\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "# Load the data using LlamaParse\n",
    "LLAMA_CLOUD_API_KEY = \"llx-I2ak5Fd5jXCnZg95khu2RqUDTNSBNmVbqYmLdwKNkkBvrVWB\"\n",
    "document_with_instruction = LlamaParse(\n",
    "    api_key=LLAMA_CLOUD_API_KEY,\n",
    "    result_type=\"markdown\", \n",
    "    parsing_instructions=\"\"\"\n",
    "This is the uploaded PDF file\n",
    "    \"\"\"\n",
    ").load_data(file_path)\n",
    "\n",
    "print(document_with_instruction)\n",
    "\n",
    "if document_with_instruction:\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for item in document_with_instruction:\n",
    "            file.write(str(item) + \"\\n\")\n",
    "else:\n",
    "    print(\"No data found in document_with_instruction\")\n",
    "\n",
    "deploy_settings = {\n",
    "    \"env\": \"production\",  # or \"staging\", \"development\"\n",
    "    \"model_name\": \"parser_model\",\n",
    "    \"model_description\": \"A parser model for extracting information from PDF files and converting to Markdown\",\n",
    "    \"compute\": {\n",
    "        \"cpu\": 2,\n",
    "        \"gpu\": 1,\n",
    "        \"memory\": 8\n",
    "    },\n",
    "    \"batch_size\": 32,\n",
    "    \"input_data_format\": \"pdf\",\n",
    "    \"output_data_format\": \"markdown\",\n",
    "    \"model_versioning\": True\n",
    "}\n",
    "\n",
    "def llama(file_contents):\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            file_path = f\"{tmp_dir}/uploaded_file.pdf\"\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file_contents)\n",
    "        LLAMA_CLOUD_API_KEY = \"llx-I2ak5Fd5jXCnZg95khu2RqUDTNSBNmVbqYmLdwKNkkBvrVWB\"\n",
    "        api_key = LLAMA_CLOUD_API_KEY\n",
    "        result = LlamaParse(api_key=api_key, result_type=\"markdown\").load_data(file_path)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "file_object = open(file_path, \"rb\")\n",
    "file_contents = file_object.read()\n",
    "mb.deploy(llama, deploy_settings, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate receiving the file content from the React frontend\n",
    "file_path = \"/home/clencyc/Dev/Llama_Parse/Package_1_Lot_2_Kulamawe_Modogashe_Consultancy_Services_Beneficial.pdf\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "mb.invoke(llama, file_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
